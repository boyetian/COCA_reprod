\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Beyer et~al.(2022)Beyer, Zhai, Royer, Markeeva, Anil, and Kolesnikov]{beyer2022knowledge}
Lucas Beyer, Xiaohua Zhai, Am{\'e}lie Royer, Larisa Markeeva, Rohan Anil, and Alexander Kolesnikov.
\newblock Knowledge distillation: A good teacher is patient and consistent.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10925--10934, 2022.

\bibitem[Cao et~al.(2023)Cao, Joshi, Gui, and Wang]{cao2023contrastive}
Shengcao Cao, Dhiraj Joshi, Liang-Yan Gui, and Yu-Xiong Wang.
\newblock Contrastive mean teacher for domain adaptive object detectors.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 23839--23848, 2023.

\bibitem[Chen et~al.(2022)Chen, Wang, Darrell, and Ebrahimi]{chen2022contrastive}
Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi.
\newblock Contrastive test-time adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 295--305, 2022.

\bibitem[Deng et~al.(2023)Deng, Xu, Li, and Duan]{deng2023harmonious}
Jinhong Deng, Dongli Xu, Wen Li, and Lixin Duan.
\newblock Harmonious teacher for cross-domain object detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 23829--23838, 2023.

\bibitem[Deng et~al.(2019)Deng, Luo, and Zhu]{deng2019cluster}
Zhijie Deng, Yucen Luo, and Jun Zhu.
\newblock Cluster alignment with a teacher for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 9944--9953, 2019.

\bibitem[D{\"o}bler et~al.(2023)D{\"o}bler, Marsden, and Yang]{dobler2023robust}
Mario D{\"o}bler, Robert~A Marsden, and Bin Yang.
\newblock Robust mean teacher for continual and gradual test-time adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7704--7714, 2023.

\bibitem[Dosovitskiy(2020)]{dosovitskiy2020image}
Alexey Dosovitskiy.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Gan et~al.(2023)Gan, Bai, Lou, Ma, Zhang, Shi, and Luo]{gan2023decorate}
Yulu Gan, Yan Bai, Yihang Lou, Xianzheng Ma, Renrui Zhang, Nian Shi, and Lin Luo.
\newblock Decorate the newcomers: Visual domain prompt for continual test time adaptation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, pages 7595--7603, 2023.

\bibitem[Ge et~al.(2023)Ge, Ren, Xu, and Yan]{ge2023unsupervised}
Pengfei Ge, Chuan-Xian Ren, Xiao-Lin Xu, and Hong Yan.
\newblock Unsupervised domain adaptation via deep conditional adaptation network.
\newblock \emph{Pattern Recognition}, 134:\penalty0 109088, 2023.

\bibitem[Grandvalet and Bengio(2004)]{grandvalet2004semi}
Yves Grandvalet and Yoshua Bengio.
\newblock Semi-supervised learning by entropy minimization.
\newblock In \emph{Advances in neural information processing systems}, 2004.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 770--778, 2016.

\bibitem[Hendrycks and Dietterich(2019)]{hendrycks2019benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock In \emph{International Conference On Learning Representations}, pages 1--11, 2019.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Basart, Mu, Kadavath, Wang, Dorundo, Desai, Zhu, Parajuli, Guo, et~al.]{hendrycks2021many}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et~al.
\newblock The many faces of robustness: A critical analysis of out-of-distribution generalization.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 8340--8349, 2021.

\bibitem[Heo et~al.(2021)Heo, Yun, Han, Chun, Choe, and Oh]{heo2021rethinking}
Byeongho Heo, Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Junsuk Choe, and Seong~Joon Oh.
\newblock Rethinking spatial dimensions of vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 11936--11945, 2021.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv preprint arXiv:1503.02531}, 2015.

\bibitem[Hu et~al.(2022)Hu, Li, Liu, Chen, Wang, and Liu]{hu2022teacher}
Chengming Hu, Xuan Li, Dan Liu, Xi Chen, Ju Wang, and Xue Liu.
\newblock Teacher-student architecture for knowledge learning: A survey.
\newblock \emph{arXiv preprint arXiv:2210.17332}, 2022.

\bibitem[Kim et~al.(2023)Kim, Sun, Raghunathan, and Kolter]{kim2023reliable}
Eungyeup Kim, Mingjie Sun, Aditi Raghunathan, and Zico Kolter.
\newblock Reliable test-time adaptation via agreement-on-the-line.
\newblock \emph{arXiv preprint arXiv:2310.04941}, 2023.

\bibitem[Lee(2024)]{lee2024entropy}
J Lee.
\newblock Entropy is not enough for test-time adaptation: From the perspective of disentangled factors.
\newblock In \emph{ICLR}, 2024.

\bibitem[Lee et~al.(2024)Lee, Jung, Lee, Park, Shin, Hwang, and Yoon]{lee2024entropy2}
Jonghyun Lee, Dahuin Jung, Saehyung Lee, Junsung Park, Juhyeon Shin, Uiwon Hwang, and Sungroh Yoon.
\newblock Entropy is not enough for test-time adaptation: From the perspective of disentangled factors.
\newblock In \emph{International Conference on Learning Representations}, pages 1--14, 2024.

\bibitem[Li et~al.(2024)Li, Yu, Du, Zhu, and Shen]{li2024comprehensive}
Jingjing Li, Zhiqi Yu, Zhekai Du, Lei Zhu, and Heng~Tao Shen.
\newblock A comprehensive survey on source-free domain adaptation.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 46\penalty0 (8):\penalty0 5743--4762, 2024.

\bibitem[Li et~al.(2023)Li, Yin, Shi, Li, Yang, and Shen]{li2023lwsis}
Xiang Li, Junbo Yin, Botian Shi, Yikang Li, Ruigang Yang, and Jianbing Shen.
\newblock Lwsis: Lidar-guided weakly supervised instance segmentation for autonomous driving.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, pages 1433--1441, 2023.

\bibitem[Liang et~al.(2024)Liang, He, and Tan]{liang2024comprehensive}
Jian Liang, Ran He, and Tieniu Tan.
\newblock A comprehensive survey on test-time adaptation under distribution shifts.
\newblock \emph{International Journal of Computer Vision}, pages 1--34, 2024.

\bibitem[Liu et~al.(2021)Liu, Kothari, Van~Delft, Bellot-Gurlet, Mordan, and Alahi]{liu2021ttt++}
Yuejiang Liu, Parth Kothari, Bastien Van~Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi.
\newblock Ttt++: When does self-supervised test-time training fail or thrive?
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 21808--21820, 2021.

\bibitem[Lu et~al.(2023)Lu, Qiu, Yu, Welleck, and Chang]{lu2022survey}
Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, and Kai-Wei Chang.
\newblock Understanding the robustness in vision transformers.
\newblock In \emph{Annual Meeting of the Association for Computational Linguistics}, pages 14605--14631, 2023.

\bibitem[Marsden et~al.(2024)Marsden, D{\"o}bler, and Yang]{marsden2024universal2}
Robert~A Marsden, Mario D{\"o}bler, and Bin Yang.
\newblock Universal test-time adaptation through weight ensembling, diversity weighting, and prior correction.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 2555--2565, 2024.

\bibitem[Mirzadeh et~al.(2020)Mirzadeh, Farajtabar, Li, Levine, Matsukawa, and Ghasemzadeh]{mirzadeh2020improved}
Seyed~Iman Mirzadeh, Mehrdad Farajtabar, Ang Li, Nir Levine, Akihiro Matsukawa, and Hassan Ghasemzadeh.
\newblock Improved knowledge distillation via teacher assistant.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, pages 5191--5198, 2020.

\bibitem[Naeini et~al.(2015)Naeini, Cooper, and Hauskrecht]{naeini2015obtaining}
Mahdi~Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht.
\newblock Obtaining well calibrated probabilities using bayesian binning.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, 2015.

\bibitem[Niu et~al.(2022)Niu, Wu, Zhang, Chen, Zheng, Zhao, and Tan]{niu2022efficient}
Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan.
\newblock Efficient test-time model adaptation without forgetting.
\newblock In \emph{International conference on machine learning}, pages 16888--16905. PMLR, 2022.

\bibitem[Niu et~al.(2023)Niu, Wu, Zhang, Wen, Chen, Zhao, and Tan]{niu2023towards}
Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan.
\newblock Towards stable test-time adaptation in dynamic wild world.
\newblock \emph{arXiv preprint arXiv:2302.12400}, 2023.

\bibitem[Niu et~al.(2024)Niu, Miao, Chen, Wu, and Zhao]{niu2024test}
Shuaicheng Niu, Chunyan Miao, Guohao Chen, Pengcheng Wu, and Peilin Zhao.
\newblock Test-time model adaptation with only forward passes.
\newblock \emph{arXiv preprint arXiv:2404.01650}, 2024.

\bibitem[Pan et~al.(2020)Pan, Shin, Rameau, Lee, and Kweon]{pan2020unsupervised}
Fei Pan, Inkyu Shin, Francois Rameau, Seokju Lee, and In~So Kweon.
\newblock Unsupervised intra-domain adaptation for semantic segmentation through self-supervision.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3764--3773, 2020.

\bibitem[Sakaridis et~al.(2021)Sakaridis, Dai, and Van~Gool]{sakaridis2021acdc}
Christos Sakaridis, Dengxin Dai, and Luc Van~Gool.
\newblock Acdc: The adverse conditions dataset with correspondences for semantic driving scene understanding.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 10765--10775, 2021.

\bibitem[Sun et~al.(2020)Sun, Wang, Liu, Miller, Efros, and Hardt]{sun2020test}
Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt.
\newblock Test-time training with self-supervision for generalization under distribution shifts.
\newblock In \emph{International conference on machine learning}, pages 9229--9248, 2020.

\bibitem[Tomani et~al.(2021)Tomani, Gruber, Erdem, Cremers, and Buettner]{tomani2021post}
Christian Tomani, Sebastian Gruber, Muhammed~Ebrar Erdem, Daniel Cremers, and Florian Buettner.
\newblock Post-hoc uncertainty calibration for domain drift scenarios.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10124--10132, 2021.

\bibitem[Venkateswara et~al.(2017)Venkateswara, Eusebio, Chakraborty, and Panchanathan]{venkateswara2017deep}
Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan.
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 5018--5027, 2017.

\bibitem[Wang et~al.(2020)Wang, Shelhamer, Liu, Olshausen, and Darrell]{wang2020tent}
Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell.
\newblock Tent: Fully test-time adaptation by entropy minimization.
\newblock \emph{arXiv preprint arXiv:2006.10726}, 2020.

\bibitem[Wang et~al.(2019)Wang, Ge, Lipton, and Xing]{wang2019learning}
Haohan Wang, Songwei Ge, Zachary Lipton, and Eric~P Xing.
\newblock Learning robust global representations by penalizing local predictive power.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Wang et~al.(2022)Wang, Fink, Van~Gool, and Dai]{wang2022continual}
Qin Wang, Olga Fink, Luc Van~Gool, and Dengxin Dai.
\newblock Continual test-time domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7201--7211, 2022.

\bibitem[Yang et~al.(2023)Yang, Lv, and Chen]{yang2023survey}
Yongquan Yang, Haijun Lv, and Ning Chen.
\newblock A survey on ensemble learning under the era of deep learning.
\newblock \emph{Artificial Intelligence Review}, 56\penalty0 (6):\penalty0 5545--5589, 2023.

\bibitem[Yin et~al.(2023)Yin, Hu, Liu, Wang, Xiang, and Zimmermann]{yin2023crossmatch}
Yifang Yin, Wenmiao Hu, Zhenguang Liu, Guanfeng Wang, Shili Xiang, and Roger Zimmermann.
\newblock Crossmatch: Source-free domain adaptive semantic segmentation via cross-modal consistency training.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 21786--21796, 2023.

\bibitem[Yuan et~al.(2023)Yuan, Xie, and Li]{yuan2023robust}
Longhui Yuan, Binhui Xie, and Shuang Li.
\newblock Robust test-time adaptation in dynamic scenarios.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 15922--15932, 2023.

\bibitem[Yuan et~al.(2024)Yuan, Xu, Hou, Sun, Shen, and Cheng]{yuan2024tea}
Yige Yuan, Bingbing Xu, Liang Hou, Fei Sun, Huawei Shen, and Xueqi Cheng.
\newblock Tea: Test-time energy adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1--11, 2024.

\bibitem[Zhang et~al.(2022)Zhang, Levine, and Finn]{zhang2022memo}
Marvin Zhang, Sergey Levine, and Chelsea Finn.
\newblock Memo: Test time robustness via adaptation and augmentation.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 38629--38642, 2022.

\bibitem[Zhang et~al.(2018)Zhang, Xiang, Hospedales, and Lu]{zhang2018deep}
Ying Zhang, Tao Xiang, Timothy~M Hospedales, and Huchuan Lu.
\newblock Deep mutual learning.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 4320--4328, 2018.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Wang, Jin, Yuan, Zhang, Wang, Jin, and Tan]{zhang2023adanpc}
Yifan Zhang, Xue Wang, Kexin Jin, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, and Tieniu Tan.
\newblock Adanpc: Exploring non-parametric classifier for test-time adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages 41647--41676, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Wang, Liang, Zhang, Yu, Wang, Tao, and Xie]{zhang2023domain}
Yi-Fan Zhang, Jindong Wang, Jian Liang, Zhang Zhang, Baosheng Yu, Liang Wang, Dacheng Tao, and Xing Xie.
\newblock Domain-specific risk minimization for domain generalization.
\newblock In \emph{Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}, pages 3409--3421, 2023{\natexlab{b}}.

\bibitem[Zhou et~al.(2022)Zhou, Liu, Qiao, Xiang, and Loy]{zhou2022domain}
Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen~Change Loy.
\newblock Domain generalization: A survey.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45\penalty0 (4):\penalty0 4396--4415, 2022.

\bibitem[Zhou et~al.(2023)Zhou, Xiao, Ye, Zhu, and Li]{zhou2023adaptive}
Lihua Zhou, Siying Xiao, Mao Ye, Xiatian Zhu, and Shuaifeng Li.
\newblock Adaptive mutual learning for unsupervised domain adaptation.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video Technology}, 33\penalty0 (11):\penalty0 6622--6634, 2023.

\end{thebibliography}
